{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this homework assignment in code cells in the iPython notebook. Include comments in your code when necessary.  Please rename the notebook as SIS ID_HW04.ipynb (your student ID number) and save the notebook once you have executed it as a PDF  (note, that when saving as PDF you don't want to use the option with latex because it crashes, but rather the one to save it directly as a PDF). \n",
    "\n",
    "For questions that ask you to make an interpretation, please write a sentence or two explaining your response. You can use \"Markdown\" language to create a cell (like this one) which is ordinary text instead of using code. To do this, create a new cell, and then look at the bar above which has a picture of a floppy disk. On the right side is a drop down menu that allows you change whether a cell is \"Markdown\" or \"Code\".\n",
    "\n",
    "**The homework should be submitted on bCourses under the Assignments tab (both the .ipynb and .pdf files). Please label it by your student ID number (SIS ID)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will verify the Central Limit Theorem and reproduced a plot I showed in class (https://en.wikipedia.org/wiki/Central_limit_theorem#/media/File:Dice_sum_central_limit_theorem.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that returns $n$ integer random numbers, uniformly disributed between 1 and 6, inclusively. This represents $n$ throws of a fair 6-sided die. The value that comes up at each throw will be called the \"score\".\n",
    "1. Generate a distribution of 100 dice throws and plot it as a  histogram normalized to unit area. Compute the mean $\\mu_1$ and standard deviation $\\sigma_1$ of this distribution. Compare your numerical result to the analytical calculation. \n",
    "1. Generate 10,000 sets of throws of $N=2,3,4,5,10$ dice, computing the total sum of dice scores for each set. For each value of $N$, plot the distribution of total scores, and compute the mean $\\mu_N$ and standard deviation $\\sigma_N$ of each distribution. This should be similar to the plot at the link above.\n",
    "1. Plot the standard deviation $\\sigma_N$ as a function of $N$. Does it follow the Central Limit Theorem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Problem 2: Parity-violating asymmetry\n",
    "\n",
    "The data sample for this problem comes from the <a href=\"http://www.slac.stanford.edu/exp/e158\">E158</a> experiment at SLAC (a national lab near that Junior university across the Bay). E158 measured a parity-violating asymmetry in Møller (electron-electron) scattering. This was a fixed-target experiment, which scattered longitudinally-polarized electrons off atomic (unpolarized) electrons in the 1.5m liquid hydrogen target. The data below contains a snapshot of 10,000 \"events\" from this experiment (overall, the experiment collected almost 400 million such events over the course of about 4 months). Each event actually records a pair of pulses: one for the right-handed electron (spin pointing along momentum) and one for the left-handed electron. For each event, we record 4 variables:\n",
    "\n",
    "* Counter: event index\n",
    "* Asymmetry: \"raw\" cross section asymmetry $A_{raw}$ from one of the detector channels (there are 50 of these overall). The cross section asymmetry is defined as \n",
    "$A_{raw} = \\frac{\\sigma_R-\\sigma_L}{\\sigma_R+\\sigma_L}$\n",
    "The asymmetry is recorded in units of PPM (parts per million). It is called \"raw\" because corrections due to the difference in beam properties at the target are not yet applied.\n",
    "* DeltaX: difference in beam position $\\Delta X=X_R-X_L$ at the target in X direction in microns (with the convention that the beam is traveling along Z)\n",
    "* DeltaY: difference in beam position $\\Delta Y=Y_R-Y_L$ at the target in Y direction in microns\n",
    "\n",
    "The data sample is provided in plain text format as the file <tt>asymdata.txt</tt>. Questions for this analysis:\n",
    "\n",
    "1. Read the data from the file, and plot distributions of $A_{raw}$, $\\Delta X$, and $\\Delta Y$. \n",
    "1. Compute the mean of the raw asymmetry distribution and its statistical uncertainty.\n",
    "1. Compute the standard deviation of the raw asymmetry distribution and its statistical uncertainty.\n",
    "1. Compute the fraction of events contained within $\\pm 1\\sigma$ of the mean, $\\pm 2\\sigma$ of the mean, and $\\pm 3\\sigma$ of the mean (where $\\sigma$ is the standard deviation you computed in Part 3). Compare these fractions with the quantiles of the Gaussian distribution (see lecture notes) ? \n",
    "1. Plot $A_{raw}$ vs $\\Delta X$, $A_{raw}$ vs $\\Delta Y$, and $\\Delta X$ vs $\\Delta Y$ as scatter plots. \n",
    "1. Compute the correlation coefficients <tt>Corr(Asym,DeltaX)</tt>, <tt>Corr(Asym,DeltaY)</tt>, and <tt>Corr(DeltaX,DeltaY)</tt>. See lecture notes, Workshop04.ipynb, Workshop05_optional.ipynb, or https://en.wikipedia.org/wiki/Pearson_correlation_coefficient for additional help understanding correlation coefficients. Which variables are approximately independent of each other ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Gamma-ray peak\n",
    "\n",
    "[Some of you may recognize this problem from Advanced Lab's Error Analysis Exercise. That's not an accident. You may also recognize this dataset in Homework05. That's not an accident either.]\n",
    "\n",
    "You are given a dataset (`peak.dat`) from a gamma-ray experiment consisting of ~1000 events. Each line in the file corresponds to one recorded gamma-ray event, and stores the the measured energy of the gamma-ray (in MeV). We will assume that the energies are randomly distributed about a common mean, and that each event is uncorrelated to others. Read the dataset from the enclosed file and:\n",
    "1. Produce a histogram of the distribution of energies. Choose the number of bins wisely, i.e. so that the width of each bin is smaller than the width of the peak, and at the same time so that the number of entries in the most populated bin is relatively large. Since this plot represents randomly-collected data, plotting error bars would be appropriate.\n",
    "1. Compute the mean and standard deviation of the distribution of energies and their statistical uncertainties. Assume the distribution is Gaussian and see the lecture notes for the formulas for the mean and variance of the sample and the formulas for the errors on these quantities. \n",
    "1. Fit the distribution to a Gaussian function using an unbinned fit (<i>Hint:</i> use <tt>scipi.stats.norm.fit()</tt> function), and compare the parameters of the fitted Gaussian with the mean and standard deviation computed in Part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import scipy.optimize as fitter\n",
    "\n",
    "\n",
    "# Once again, feel free to play around with the matplotlib parameters\n",
    "plt.rcParams['figure.figsize'] = 8,4\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "\n",
    "energies = np.loadtxt('peak.dat') # MeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall `plt.hist()` isn't great when you need error bars, so it's better to first use [`np.histogram()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html) -- which returns the counts in each bin, along with the edges of the bins (there are $n + 1$ edges for $n$ bins).  Once you find the bin centers and errors on the counts, you can make the actual plot with [`plt.bar()`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.bar.html).  Start with something close to `bins = 25` as the second input parameter to `np.histogram()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use numpy.histogram to get the counts and bin edges\n",
    "\n",
    "# bin_centers = 0.5*(bin_edges[1:]+bin_edges[:-1]) works for finding the bin centers\n",
    "\n",
    "# assume Poisson errors on the counts – errors go as the square root of the count\n",
    "\n",
    "# now use plt.bar() to make the histogram with error bars (remember to label the plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and standard deviation of the list of `energies` and their uncertainties\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the list of `energies` directly as input to `scipy.stats.norm.fit()`; the returned values are the mean and standard deviation of a fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean and standard deviation using scipy.stats.norm.fit()\n",
    "# Compare these to those computed in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
